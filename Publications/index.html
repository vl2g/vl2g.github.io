<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
  <title> VL2G @ IITJ</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" \
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" type="text/css" href="/static/css/vl2g.css">
  <link href="http://fonts.googleapis.com/css?family=Open+Sans:400,700,600" rel="stylesheet" type="text/css">
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
			<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
			<![endif]-->
</head>

<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date(); a = s.createElement(o),
      m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
  })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'UA-85595941-1', 'auto');
  ga('send', 'pageview');

</script>

<body>


  <header>
    <nav class="navbar navbar-default mall-navbar">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar"
            aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand navbar-left" href="/"><span class="nav-name hidden-xs hidden-sm">
              <p style="color:white;">Vision, Language and Learning Group (VL2G) @ IITJ</p>
            </span>
            <h3 class="abbr-navbar-brand hidden-md hidden-lg hidden-xl" style="line-height: 0px;">
              <p style="color:white;"> VL2G @ IITJ
            </h3>
          </a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav navbar-right">
            <li><a href="/">
                <p style="color:white;">HOME</p>
              </a></li>
            <li><a href="/people/">
                <p style="color:white;">PEOPLE</p>
              </a></li>
            <li><a href="/Publications/">
                <p style="color:white;">PUBLICATIONS</p>
              </a></li>
            <li><a href="/gallery/">
                <p style="color:white;">GALLERY</p>
              </a></li>
            <!-- <li><a href="/teaching/">teaching</a></li>
				<li><a href="/news/">news</a></li> -->
            <!-- <li><a href="/resources/">resources</a></li>
				<li><a href="/demos/">demos</a></li> -->
            <!-- <li><a href="/gallery/">gallery</a></li> -->

          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>
  </header>





  <div class="container content">
	  <li> When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering
      using Small VLMs<br />
      Abhirama Subramanyam Penamakuri*, Navlika Singh*, Piyush Arora*, Anand Mishra. (*: equal contribution)
      <br />
      <i> <b>EMNLP 2025.</b><span class="blinking">(NEW)</span> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://arxiv.org/abs/2509.16633">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/MPA">Code</a>]
    <br /> <br />
	  
    <li> Aligning Moments in Time using Video Queries<br />
      Yogesh Kumar*, Uday Agarwal*, Manish Gupta, Anand Mishra. (*: equal contribution)
      <br />
      <i> <b>ICCV 2025</b><span class="blinking">(NEW)</span> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://arxiv.org/pdf/2508.15439">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/MATR">Code</a>]
    <br /> <br />
    

    <li> Audiopedia: Audio QA with Knowledge,<br />
      Abhirama Subramanyam Penamakuri*, Kiran Chhatre*, Akshat Jain.
      <br />
      <i> <b>ICASSP 2025.</b><span class="blinking">(NEW)</span> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://ieeexplore.ieee.org/abstract/document/10889814">Paper</a>]

    [<a target="_blank" rel="nofollow" href="https://abhiram4572.github.io/projects/audiopedia/">Project Page</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/Abhiram4572/Audiopedia">Data</a>]
    <br /> <br />


    <li> PatentLMM: Large Multimodal Model for Generating Descriptions for Patent Figures,<br />
      Shreya Shukla*, Nakul Sharma*, Manish Gupta, Anand Mishra.
      <br />
      <i> <b>AAAI 2025.</b><span class="blinking">(NEW)</span> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://anandmishra22.github.io/files/Shreya-AAAI25.pdf">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://vl2g.github.io/projects/PatentLMM/">Project Page</a>]
    <br /> <br />

    <li> Chapter-Based Video Moment Retrieval using Natural Language Queries,<br />
      Uday Agarwal*, Yogesh Kumar*, Abu Shahid*, Prajwal Gatti, Manish Gupta, Anand Mishra.
      <br />
      <i> <b>ICVGIP 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow"
      href="https://drive.google.com/file/d/143odnhV4CljwX8Y8hZAPThkLbEVJtEdv/view?usp=sharing">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/ChapVidMR">Code</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/ChapVidMR/tree/main/data">Data</a>]
    <br /> <br />

    <li> Visual Text Matters: Improving Text-KVQA with Visual Text Entity Knowledge-aware Large Multimodal
      Assistant,<br />
      Abhirama Subramanyam Penamakuri, Anand Mishra.
      <br />
      <i> <b>EMNLP 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://anandmishra22.github.io/files/Abhirama-EMNLP24.pdf">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://vl2g.github.io/projects/LMM4Text-KVQA/">Project Page</a>]
    <br /> <br />


    <li> Show Me the World in My Language: Establishing the First Baseline for Scene-Text to Scene-Text
      Translation,<br />
      Shreyas Vaidya*, Arvind Kumar Sharma*, Prajwal Gatti, Anand Mishra. (*: equal contribution)
      <br />
      <i> <b>ICPR 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://arxiv.org/pdf/2308.03024">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://vl2g.github.io/projects/visTrans/">Project Page</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/Bhashini-IITJ/visualTranslation/">Code</a>]

    <br /> <br />



    <li> Sketch-guided Image Inpainting with Partial Discrete Diffusion Process,<br />
      Nakul Sharma, Aditay Tripathi, Anirban Chakraborty, Anand Mishra
      <br />
      <i> <b>CVPR Workshop 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="https://arxiv.org/pdf/2404.11949.pdf">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/Sketch-Inpainting.git">Code</a>]

    <br /> <br />

    <li> QDETRv: Query-Guided DETR for One-Shot Object Localization in Videos,<br />
      Yogesh Kumar, Saswat Mallick, Anand Mishra, Sowmya Rasipuram, Anutosh Maitra, Roshni Ramnani
      <br />
      <i> <b>AAAI 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="./files/Kumar-AAAI24.pdf">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/yogesh-iitj/QDETRV">Code</a>]
    <br /> <br />

    <li> Composite Sketch+Text Queries for Retrieving Objects with Elusive Names and Complex Interactions, <br />
      Prajwal Gatti, Kshitij Parikh, Dhriti Paul, Manish Gupta, Anand Mishra.
      <br />
      <i> <b>AAAI 2024.</b> <br />
    </li>
    [<a target="_blank" rel="nofollow" href="./files/Gatti-AAAI24.pdf">Paper</a>]
    [<a target="_blank" rel="nofollow" href="https://github.com/vl2g/CSTBIR">Code</a>]
    <br /> <br />

    <li> Answer Mining from a Pool of Images: Towards Retrieval-Based Visual Question Answering,
      <br />
      Abhirama Subramanyam Penamakuri, Anand Mishra, Manish Gupta, Mithun Das Gupta,<br />
      <i> <b>IJCAI 2023. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://drive.google.com/file/d/1yANgw3vPpnwRiGKMPjIWWt_kzEMEPjb_/view?pli=1">Paper</a>][<a
          target="_blank" rel="nofollow" href="https://vl2g.github.io/projects/retvqa/">Project Page</a>][<a
          target="_blank" rel="nofollow" href="https://github.com/Abhiram4572/mi_bart">Code</a>]
    </li>
    <br />

    <li> Towards Making Flowchart Images Machine Interpretable,
      <br />
      Shreya Shukla, Prajwal Gatti, Yogesh Kumar, Vikash Yadav, Anand Mishra,<br />
      <i> <b>ICDAR 2023. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/floco/docs/FLOCO-ICDAR2023.pdf">Paper</a>][<a target="_blank"
          rel="nofollow" href="https://vl2g.github.io/projects/floco/">Project Page</a>][<a target="_blank"
          rel="nofollow" href="https://github.com/vl2g/floco">Code</a>]
    </li>
    <br />


    <li> Few-Shot Referring Relationships in Videos,
      <br />
      Yogesh Kumar, Anand Mishra,<br />
      <i> <b>CVPR 2023. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/refRelations/docs/paper.pdf">Paper</a>][<a target="_blank"
          rel="nofollow" href="https://vl2g.github.io/projects/refRelations/">Project Page</a>][<a target="_blank"
          rel="nofollow" href="https://github.com/vl2g/RefRelations">Code</a>]
    </li>
    <br />

    <li> Contrastive Multi-View Textual-Visual Encoding:
      Towards One Hundred Thousand-Scale One-Shot Logo Identification,
      <br />
      Nakul Sharma, Abhirama Subramanyam Penamakuri, Anand Mishra,<br />
      <i> <b>ICVGIP 2022. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/logoIdent/index_files/78.pdf">Paper</a>][<a target="_blank"
          rel="nofollow" href="https://vl2g.github.io/projects/logoIdent/">Project Page</a>][<a target="_blank"
          rel="nofollow" href="https://github.com/thisis-nkul/one-shot-logo_icvgip">Code</a>]
    </li>
    <br />

    <li> VISTOT: Vision-Augmented Table-to-Text Generation,
      <br />
      Prajwal Gatti, Anand Mishra, Manish Gupta, Mithun Das Gupta,<br />
      <i> <b>EMNLP 2022. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/vistot/docs/VISTOT-EMNLP2022.pdf">Paper</a>][<a target="_blank"
          rel="nofollow" href="https://vl2g.github.io/projects/vistot/">Project Page</a>][<a target="_blank"
          rel="nofollow" href="https://github.com/vl2g/visToT">Code</a>]
    </li>
    <br />




    <li> COFAR: Commonsense and Factual Reasoning in Image Search
      <br />
      Prajwal Gatti, Abhirama Subramanyam Penamakuri, Revant Teotia, Anand Mishra, Shubhashis Sengupta, Roshni
      Ramnani<br />
      <i> <b>AACL-IJCNLP 2022. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/cofar/docs/COFAR-AACL2022.pdf">Paper</a>][<a target="_blank"
          rel="nofollow" href="https://vl2g.github.io/projects/cofar/">Project Page</a>][<a target="_blank"
          rel="nofollow" href="https://github.com/vl2g/cofar">Code</a>]
    </li>
    <br />


    <li> Few-shot Visual Relationship Co-localization
      ,<br />
      Revant Teotia*, Vaibhav Mishra*, Mayank Maheshwari*, Anand Mishra,<br />
      <i> <b>ICCV 2021. </b> <br />
        [<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/vrc/docs/VRC-ICCV2021.pdf">Paper</a>][<a target="_blank" rel="nofollow"
          href="https://vl2g.github.io/projects/vrc/">Project Page</a>][<a target="_blank" rel="nofollow"
          href="https://github.com/vl2g/VRC">Code</a>]
        (*: equal contribution)
    </li>
    <br />


    <li> Look, Attend and Ask: Learning to Ask Questions by Reading Text in Images, <br />
      Soumya Jahagirdar, Shankar Gangisetty, Anand Mishra<br />
      <i> <b>ICDAR 2021 </b>. <br />
        [<a target="_blank" rel="nofollow" href="./files/">Paper</a>]
    </li>
    <br />



    <li>
      Sketch-Guided Object Localization in Natural Images,</span><br />
      Aditay Tripathi, Rajath R. Dani, Anand Mishra, Anirban Chakraborty<br />
      <i> <b>ECCV 2020 (Spotlight Presentation)</b>. <br />
        [<a target="_blank" rel="nofollow" href="./files/TripathiECCV2020.pdf">Paper</a>] [<a target="_blank"
          rel="nofollow" href='./files/ECCV2020.bib'>bibtex</a>]
        [<a href="http://visual-computing.in/sketch-guided-object-localization/">Project page</a>][<a
          href="https://github.com/IISCAditayTripathi/SketchGuidedLocalization">Code</a>]
        [<a href="https://www.youtube.com/watch?v=vI0NEVytLfU">Know the paper in 90 seconds</a>] [<a
          href="https://www.youtube.com/watch?v=5gBDPbbvssk">Know the paper in ten minutes</a>]
    </li>
    <br />

    <li>
      From Strings to Things: Knowledge-enabled VQA model that can read and reason,</span><br />
      Ajeet Kumar Singh, Anand Mishra, Shashank Shekhar, and Anirban Chakraborty<br />
      <i> <b>ICCV 2019 (oral)</b>. <br />
        [<a target="_blank" rel="nofollow" href="https://textkvqa.github.io/docs/textKVQA_ICCV2019.pdf">Paper</a>] [<a
          target="_blank" rel="nofollow" href='./files/ICCV2019.bib'>bibtex</a>]
        [<a href="https://textkvqa.github.io">Project page</a>]
    </li>



  </div>


  <footer class="widewrapper footer">
    <div class="container">
      <div class="row footer">
        <div class="col-sm-4">
          <div style="display: flex; justify-content: center;">
            <a href="http://www.iitj.ac.in"> <img src="/iitjlogo-with-name.png" style="height:100px"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
  <!-- Include all compiled plugins (below), or include individual files as needed -->
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" \
    integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
    crossorigin="anonymous"></script>
</body>

</html>
